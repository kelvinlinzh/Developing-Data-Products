storm <- read.csv("./repdata-data-StormData.csv.bz2")
storm_sub<-subset(storm,select=c("EVTYPE","FATALITIES","INJURIES","PROPDMG","PROPDMGEXP","CROPDMG","CROPDMGEXP"))
x <- storm_sub$EVTYPE
evtypes <- gsub(" ", "", tolower(x))
storm_sub$EVTYPENEW <- evtypes
# Map the PROPDMG to dollar amount by mapping the PROPDMGEXP field
storm_sub$PROPDMGEXP <- tolower(storm_sub$PROPDMGEXP)
storm_sub$PROPDMGEXP <- ifelse(storm_sub$PROPDMGEXP == 'h', 100 , ifelse (storm_sub$PROPDMGEXP == 'k', 1000, ifelse(storm_sub$PROPDMGEXP == 'm', 1000000, ifelse(storm_sub$PROPDMGEXP == 'b', 1000000000, 1))))
storm_sub$PROPDMGDOLLAR <- storm_sub$PROPDMG * storm_sub$PROPDMGEXP
# Map the CROPDMG to dollar amount by mapping the CROPDMGEXP field
storm_sub$CROPDMGEXP <- tolower(storm_sub$CROPDMGEXP)
storm_sub$CROPDMGEXP <- ifelse(storm_sub$CROPDMGEXP == 'h', 100 , ifelse (storm_sub$CROPDMGEXP == 'k', 1000, ifelse(storm_sub$CROPDMGEXP == 'm', 1000000, ifelse(storm_sub$CROPDMGEXP == 'b', 1000000000, 1))))
storm_sub$CROPDMGDOLLAR <- storm_sub$CROPDMG * storm_sub$CROPDMGEXP
#Create a new field of total property and crop damage
storm_sub$TOTDMGDOLLAR <- storm_sub$CROPDMGDOLLAR + storm_sub$PROPDMGDOLLAR
View(storm_sub)
health <- arrange(health , desc(FATALITIES))
health2 <- health[1:10,]
#Plot bar graph of top 10 fatal events
ggplot(data=health2, aes(x=reorder(EVTYPENEW, FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity", fill="steelblue") +
coord_flip() +
xlab("") +
ggtitle("Fatalities by Event Type (Top 10)") +
theme(axis.text = element_text(size = 15)) +
theme_bw()
health <- aggregate (cbind(FATALITIES, INJURIES)~ EVTYPENEW, FUN=sum, data = storm_sub, na.rm=TRUE)
#Filter out the top 10 fatal events
health <- arrange(health , desc(FATALITIES))
health2 <- health[1:10,]
#Plot bar graph of top 10 fatal events
ggplot(data=health2, aes(x=reorder(EVTYPENEW, FATALITIES), y=FATALITIES)) +
geom_bar(stat="identity", fill="steelblue") +
coord_flip() +
xlab("") +
ggtitle("Fatalities by Event Type (Top 10)") +
theme(axis.text = element_text(size = 15)) +
theme_bw()
#Filter out the top 10 injuries events
health <- arrange(health , desc(INJURIES))
health3 <- health[1:10,]
#Plot bar graph of top 10 injuries events
ggplot(data=health3, aes(x=reorder(EVTYPENEW, INJURIES), y=INJURIES)) +
geom_bar(stat="identity", fill="steelblue") +
coord_flip() +
xlab("") +
ggtitle("Injuries by Event Type (Top 10)") +
theme(axis.text = element_text(size = 15)) +
theme_bw()
damages <- aggregate(PROPDMGNUM + CROPDMGNUM ~ EVTYPE, data=tidyStormData, FUN=sum, na.rm=TRUE)
#Filter out the top 10 economic impact events
damages <- arrange(damages, desc(PROPDMGNUM))
damages3 <- damages[1:10]
#Plot bar graph of top 10 Property Damage events
ggplot(data=damages3, aes(x=reorder(EVTYPENEW, PROPDMG), y=PRODMG)) +
geom_bar(stat="identity", fill="steelblue") +
coord_flip() +
xlab("") +
ggtitle("Property Damage by Event Type (Top 10)") +
theme(axis.text = element_text(size = 15)) +
theme_bw()
damages <- aggregate(PROPDMGNUM + CROPDMGNUM ~ EVTYPE, data=tidyStormData, FUN=sum, na.rm=TRUE)
damages <- aggregate(PROPDMGNUM + CROPDMGNUM ~ EVTYPE, data=storm_sub, FUN=sum, na.rm=TRUE)
damages <- aggregate(TOTDMGDOLLAR ~ EVTYPE, data=storm_sub, FUN=sum, na.rm=TRUE)
#Filter out the top 10 economic impact events
damages <- arrange(damages, desc(TOTDMGDOLLAR))
damages3 <- damages[1:10]
#Plot bar graph of top 10 Property Damage events
ggplot(data=damages3, aes(x=reorder(EVTYPENEW, TOTDMGDOLLAR), y=TOTDMGDOLLAR)) +
geom_bar(stat="identity", fill="steelblue") +
coord_flip() +
xlab("") +
ggtitle("Total Damage in Dollars by Event Type (Top 10)") +
theme(axis.text = element_text(size = 15)) +
theme_bw()
damages <- arrange(damages, desc(TOTDMGDOLLAR))
damages3 <- damages[1:10,]
ggplot(data=damages3, aes(x=reorder(EVTYPENEW, TOTDMGDOLLAR), y=TOTDMGDOLLAR)) +
geom_bar(stat="identity", fill="steelblue") +
coord_flip() +
xlab("") +
ggtitle("Total Damage in Dollars by Event Type (Top 10)") +
theme(axis.text = element_text(size = 15)) +
theme_bw()
```{r, echo=TRUE}
damages <- aggregate(TOTDMGDOLLAR ~ EVTYPENEW, data=storm_sub, FUN=sum, na.rm=TRUE)
#Filter out the top 10 economic impact events
damages <- arrange(damages, desc(TOTDMGDOLLAR))
damages3 <- damages[1:10,]
#Plot bar graph of top 10 Property Damage events
ggplot(data=damages3, aes(x=reorder(EVTYPENEW, TOTDMGDOLLAR), y=TOTDMGDOLLAR)) +
geom_bar(stat="identity", fill="steelblue") +
coord_flip() +
xlab("") +
ggtitle("Total Damage in Dollars by Event Type (Top 10)") +
theme(axis.text = element_text(size = 15)) +
theme_bw()
file.edit('~/.Rprofile'
file.edit('~/.Rprofile')
options(rpubs.upload.method = "internal")
options(rpubs.upload.method = "internal")
options(rpubs.upload.method = "internal")
```{r}
echo = TRUE  # Always make code visible
library(knitr)
library(ggplot2)
set.seed(1)
```
echo = TRUE  # Always make code visible
library(knitr)
library(ggplot2)
set.seed(1)
n <- 40 # we will be using 40 exponentials
lambda <- 0.2 # lambda is 0.2
sim <- 1000 # we will be running 1000 simulations
TMean = 1/lambda
TStdDev = ((1/lambda) * (1/sqrt(n)))
TVar = TStdDev^2
data <- matrix(rexp(n*sim, lambda), sim)
row_means <- apply(data,1,mean)
emp_mean <- mean(row_means)
emp_sd <- sd(row_means)
emp_var <- var(row_means)
emp_mean
TMean
emp_var
TVar
emp_var
TVar
emp_sd
TStdDev
dfrm <- data.frame(row_means)
ggplot(dfrm,aes(x=row_means)) +  geom_histogram(binwidth = lambda,fill="yellow",color="black",aes(y = ..density..)) +  labs(title="Plot of 40 Exponential Distributions", x="Averages of 40 Distributions", y="Density") + geom_vline(xintercept=emp_mean,size=3.0, color="black") +  stat_function(fun=dnorm,args=list(mean=emp_mean, sd=emp_sd),color = "blue", size = 2.0) +  geom_vline(xintercept=TMean,size=1.0,color="green",linetype = "dashed", size=3.0) +  stat_function(fun=dnorm,args=list(mean=TMean, sd=TStdDev),color = "black", size = 1.0)
dfrm <- data.frame(row_means)
ggplot(dfrm,aes(x=row_means)) +  geom_histogram(binwidth = lambda,fill="yellow",color="black",aes(y = ..density..)) +  labs(title="Plot of 40 Exponential Distributions", x="Averages of 40 Distributions", y="Density") + geom_vline(xintercept=emp_mean,size=3.0, color="black") +  stat_function(fun=dnorm,args=list(mean=emp_mean, sd=emp_sd),color = "pink", size = 2.0) +  geom_vline(xintercept=TMean,size=1.0,color="green",linetype = "dashed", size=3.0) +  stat_function(fun=dnorm,args=list(mean=TMean, sd=TStdDev),color = "black", size = 1.0)
dfrm <- data.frame(row_means)
ggplot(dfrm,aes(x=row_means)) +  geom_histogram(binwidth = lambda,fill="yellow",color="black",aes(y = ..density..)) +  labs(title="Plot of 40 Exponential Distributions", x="Averages of 40 Distributions", y="Density") + geom_vline(xintercept=emp_mean,size=3.0, color="black") +  stat_function(fun=dnorm,args=list(mean=emp_mean, sd=emp_sd),color = "green", size = 1.0) +  geom_vline(xintercept=TMean,size=1.0,color="green",linetype = "dashed", size=3.0) +  stat_function(fun=dnorm,args=list(mean=TMean, sd=TStdDev),color = "black", size = 1.0)
echo = TRUE
library(knitr)
library(ggplot2)
data(ToothGrowth)
head(ToothGrowth)
str(ToothGrowth)
mean(ToothGrowth$len)
sd(ToothGrowth$len)
plot <- ggplot(ToothGrowth, aes(x=factor(dose),y=len,fill=factor(dose)))
plot + geom_boxplot(notch=F) + facet_grid(.~supp) +
scale_x_discrete("Dosage (Milligram)") +
scale_y_continuous("Tooth Length") +
ggtitle("Effect of Dosage and Supplement Type on Tooth Growth")
t.test(len~supp, paired=F, var.equal=F, data=ToothGrowth)
t.test(len ~ dose, paired = F, var.equal = F, data = subset(ToothGrowth,ToothGrowth$dose!="2"))
t.test(len ~ dose, paired = F, var.equal = F, data = subset(ToothGrowth,ToothGrowth$dose!="0.5"))
se <- sqrt((1.5^2*8+1.8^2*8)/16 * (1/9 +1/9))
z <- (-3+1) / se
pvalue <- pnorm(z) * 2
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc
set.seed(1234)
library(caret)
library(e1071)
library(randomForest)
install.packages("e1071")
install.packages("randomForest")
set.seed(1234)
library(caret)
library(e1071)
library(randomForest)
#Results hidden
data <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
colnames(data)
summary(data)
```{r, echo=FALSE}
train <- createDataPartition(y=data$classe,p=.70,list=F)
training <- data[train,]
testing <- data[-train,]
```
Cl <- grep("name|timestamp|window|X", colnames(training), value=F)
trainingCl <- training[,-Cl]
trainingCl[trainingCl==""] <- NA
NArate <- apply(trainingCl, 2, function(x) sum(is.na(x)))/nrow(trainingCl)
trainingCl <- trainingCl[!(NArate>0.95)]
summary(trainingCl)
preProc <- preProcess(trainingCl[,1:52],method="pca",thresh=.8) #12 components are required
preProc
preProc <- preProcess(trainingCl[,1:52],method="pca",thresh=.9) #18 components are required
preProc
preProc <- preProcess(trainingCl[,1:52],method="pca",thresh=.95) #25 components are required
preProc
preProc <- preProcess(trainingCl[,1:52],method="pca",pcaComp=25) #Use 25 components to achieve 95% of variance
preProc
preProc
preProc$rotation
trainingPC <- predict(preProc,trainingCl[,1:52])
modFitRF <- randomForest(trainingCl$classe ~ .,   data=trainingPC, do.trace=F)
print(modFitRF) # view results
importance(modFitRF) # importance of each predictor
preProc$rotation
trainingPC <- predict(preProc,trainingCl[,1:52])
modFitRF <- randomForest(trainingCl$classe ~ .,   data=trainingPC, do.trace=F)
print(modFitRF) # view results
importance(modFitRF) # importance of each predictor
testingCl <- testing[,-Cl]
testingCl[testingCl==""] <- NA
NArate <- apply(testingCl, 2, function(x) sum(is.na(x)))/nrow(testingCl)
testingCl <- testingCl[!(NArate>0.95)]
testingPC <- predict(preProc,testingCl[,1:52])
confusionMatrix(testingCl$classe,predict(modFitRF,testingPC))
testdata <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
testdataCl <- testdata[,-Cl]
testdataCl[testdataCl==""] <- NA
NArate <- apply(testdataCl, 2, function(x) sum(is.na(x)))/nrow(testdataCl)
testdataCl <- testdataCl[!(NArate>0.95)]
testdataPC <- predict(preProc,testdataCl[,1:52])
testdataCl$classe <- predict(modFitRF,testdataPC)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(testdataCl$classe)
setwd("~/GitHub/Practical-Machine-Learning/Answers")
pml_write_files(answers)
setwd("C:/Users/Kelvin Lin/datasciencecoursera")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
table(vowel.train$y)
set.seed(33833)
require(caret)
M1 <- train(y ~ ., data=vowel.train, method="rf")
M2 <- train(y ~ ., data=vowel.train, method="gbm")
hat1 <- predict(M1, vowel.test)
hat2 <- predict(M2, vowel.test)
confusionMatrix(hat1, vowel.test$y)$overall
confusionMatrix(hat2, vowel.test$y)$overall
hat <- data.frame(hat1,
hat2,
y = vowel.test$y,
agree = hat1 == hat2)
accuracy <- sum(hat1[hat$agree] == hat$y[hat$agree]) / sum(hat$agree)
accuracy
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
table(vowel.train$y)
set.seed(33833)
require(caret)
M1 <- train(y ~ ., data=vowel.train, method="rf")
M2 <- train(y ~ ., data=vowel.train, method="gbm")
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
fit1 <- train(y ~ ., data = vowel.train, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
M1 <- train(diagnosis ~ ., data=training, method="rf")
M2 <- train(diagnosis ~ ., data=training, method="gbm")
M3 <- train(diagnosis ~ ., data=training, method="lda")
hat1 <- predict(M1, testing)
hat2 <- predict(M2, testing)
hat3 <- predict(M3, testing)
hat <- data.frame(hat1, hat2, hat3, diagnosis=testing$diagnosis)
M4 <- train(diagnosis ~ ., data=hat, method="rf")
M4
hat4 <- predict(M4, testing)
confusionMatrix(hat1, testing$diagnosis)$overall
confusionMatrix(hat2, testing$diagnosis)$overall
confusionMatrix(hat3, testing$diagnosis)$overall
confusionMatrix(hat4, testing$diagnosis)$overall
library(lubridate)  # For year() function below
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
dat = read.csv(url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
require(forecast)
M <- bats(tstrain)
M
hat <- forecast(M, length(testing$visitsTumblr))
hat <- cbind(testing, data.frame(hat))
hat$isIn95 <- hat$Lo.95 < hat$visitsTumblr & hat$visitsTumblr < hat$Hi.95
prop.table(table(hat$isIn95))
install.packages("lubridate")
library(lubridate)  # For year() function below
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
dat = read.csv(url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
require(forecast)
M <- bats(tstrain)
M
hat <- forecast(M, length(testing$visitsTumblr))
hat <- cbind(testing, data.frame(hat))
hat$isIn95 <- hat$Lo.95 < hat$visitsTumblr & hat$visitsTumblr < hat$Hi.95
prop.table(table(hat$isIn95))
install.packages("forecast")
library(lubridate)  # For year() function below
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
dat = read.csv(url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
require(forecast)
M <- bats(tstrain)
M
hat <- forecast(M, length(testing$visitsTumblr))
hat <- cbind(testing, data.frame(hat))
hat$isIn95 <- hat$Lo.95 < hat$visitsTumblr & hat$visitsTumblr < hat$Hi.95
prop.table(table(hat$isIn95))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
M <- svm(CompressiveStrength ~ ., data=training)
testing$hat <- predict(M, testing)
testing$error <- testing$CompressiveStrength - testing$hat
rmse <- sqrt(mean(testing$error ^ 2))
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Property Hunter"),
sidebarPanel(
h4('Property'),
textInput('text', 'Address', value=''),
numericInput('price', 'Price ($)', 550000),
numericInput('weeklyRent', 'Weekly Rent ($)', 550),
h5('Costs'),
numericInput('weeklyRepayments', 'Weekly Repayments ($ per week)', 503),
numericInput('strataPerQuarter', 'Strata ($ per quarter)', 1050),
numericInput('councilPerQuarter', 'Council ($ per quarter)', 163),
numericInput('waterPerQuarter', 'Water ($ per quarter)', 180),
numericInput('managementFees', 'Management Fees ($ per week)', 38)
),
mainPanel(
h4('Rental Yield (%)'),
textOutput("rentalYield"),
h4('Cashflow Per Week ($)'),
textOutput("cashflowPerWeek"),
h4('Cashflow Per Year ($)'),
textOutput("cashflowPerYear"),
br(),
h4('Instructions'),
helpText("This application is for property investors to calculate the rental yield of a property and estimate the cashflow of owning the property. Your real estate agent and mortgage broker will be able to help you with the numbers."),
code("Rental Yield"),
helpText("Enter the property's price and expected weekly rental income to calculate the rental yield."),
code("Cashflow"),
helpText("Enter the property's holding costs to estimate the cashflow of owning the property.")
)
))
install.packages("shiny")
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Property Hunter"),
sidebarPanel(
h4('Property'),
textInput('text', 'Address', value=''),
numericInput('price', 'Price ($)', 550000),
numericInput('weeklyRent', 'Weekly Rent ($)', 550),
h5('Costs'),
numericInput('weeklyRepayments', 'Weekly Repayments ($ per week)', 503),
numericInput('strataPerQuarter', 'Strata ($ per quarter)', 1050),
numericInput('councilPerQuarter', 'Council ($ per quarter)', 163),
numericInput('waterPerQuarter', 'Water ($ per quarter)', 180),
numericInput('managementFees', 'Management Fees ($ per week)', 38)
),
mainPanel(
h4('Rental Yield (%)'),
textOutput("rentalYield"),
h4('Cashflow Per Week ($)'),
textOutput("cashflowPerWeek"),
h4('Cashflow Per Year ($)'),
textOutput("cashflowPerYear"),
br(),
h4('Instructions'),
helpText("This application is for property investors to calculate the rental yield of a property and estimate the cashflow of owning the property. Your real estate agent and mortgage broker will be able to help you with the numbers."),
code("Rental Yield"),
helpText("Enter the property's price and expected weekly rental income to calculate the rental yield."),
code("Cashflow"),
helpText("Enter the property's holding costs to estimate the cashflow of owning the property.")
)
))
library(shiny)
shinyServer(
function(input, output){
output$rentalYield <- renderText({ calculateRentalYield(input$weeklyRent, input$price) })
output$cashflowPerYear <- renderText({calculateYearlyCashflow(input$weeklyRent, input$strataPerQuarter, input$councilPerQuarter, input$waterPerQuarter, input$managementFees, input$weeklyRepayments)})
output$cashflowPerWeek <- renderText({calculateWeeklyCashflow(input$weeklyRent, input$strataPerQuarter, input$councilPerQuarter, input$waterPerQuarter, input$managementFees, input$weeklyRepayments)})
}
)
calculateRentalYield <- function (weeklyRent, propertyPrice)
{
result <- weeklyRent * 52 / propertyPrice * 100
return(round(result, digits = 2))
}
calculateYearlyCashflow <- function(weeklyRent, strata, council, water, managementFees, weeklyRepayments)
{
result <- weeklyRent * 52 - (strata + council + water) * 4 - managementFees * 52 - weeklyRepayments * 52
return(round(result, digits = 2))
}
calculateWeeklyCashflow <- function(weeklyRent, strata, council, water, managementFees, weeklyRepayments)
{
result <- (weeklyRent * 52 - (strata + council + water) * 4 - managementFees * 52 - weeklyRepayments * 52) / 52
return(round(result, digits = 2))
}
runApp
install.packages('devtools')
install.packages("shinyapps")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='mycourseraassignment', token='C5A146C2A8E913CEA1A1FD8D273348DA', secret='ae5olYJ4TLybMTiI+tapvQBueKZK3kWQJiY2pK4R')
devtools::install_github('rstudio/shinyapps')
runApp()
library(shiny)
runApp()
setwd("C:/Users/Kelvin Lin/datasciencecoursera/DevelopingDataProducts")
runApp()
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
setwd("C:/Users/Kelvin Lin/datasciencecoursera")
setwd("C:/Users/Kelvin Lin/datasciencecoursera/Developing-Data-Products")
author("first_deck")
library(slidify)
install_github('slidify', 'ramnathv/slidify')
install_github('slidify', 'ramnathv')
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
library(slidify)
remove.packages(slidifyLibraries)
remove.packages('slidifyLibraries')
install_github('ramnathv/slidifyLibraries')
library(slidify)
remove.packages(slidify)
remove.packages('slidify'')
remove.packages('slidify)
remove.packages('slidify')
remove.packages('slidifyLibraries')
remove.packages('slidify')
install_github('ramnathv/slidifyLibraries')
install_github('ramnathv/slidify')
library(slidify)
